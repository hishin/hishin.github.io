<html>
   <head>
      <meta charset="utf-8" name="keywords" content="Human Computer Interaction, Computer Graphics, Interface for Audio visual Media">
      <title>Valentina Shin</title>
      <link rel="stylesheet" href="webstyle.css" />
      <!-- Google Web Fonts -->
      <link href="https://fonts.googleapis.com/css?family=Amatic+SC|Patua+One&display=swap" rel="stylesheet">
   </head>
   <body>
      <div id="wrap">
      <div id="header">
         <div id="header_content">
            <div class="name"> Valentina Shin</div>
            <p class="affiliate">
               Senior Research Scientist
               <br>
               Adobe Research
               <br>
               One Broadway, Cambridge MA 02142
               <br>
               vshin [at] adobe [dot] com
            </p>
         </div>
         <!--end of header_content-->
         <div>
            <img src="profile_2023.jpg" class="profile-image">
         </div>
         <!--end of header_picture-->
         <div id="intro">
            <p>
               <br>
               I am a senior research scientist at
               <a href="https://research.adobe.com/">Adobe Research</a>.
               <br><br>
               I build systems that combine algorithms with novel user interactions made possible by those algorithms.
               <br>
               My primary focus is audiovisual media—especially video. I'm passionate about helping people create compelling video stories, communicate more effectively through video, and engage with video content in smarter, more meaningful ways.
               <br><br>
               I received my PhD in Computer Science from MIT, where I was advised by 
               <a href="https://people.csail.mit.edu/fredo/">Fredo Durand</a> in the 
               <a href="http://graphics.csail.mit.edu/">Computer Graphics Lab</a>.
               <br>
               Before joining MIT, I completed my B.S. in Computer Science at Princeton University, 
               working with <a href="https://www.cs.princeton.edu/~funk/">Thomas Funkhouser</a>.
            </p>
         </div>
         <!--end of intro-->
      </div>
      <!--end of header-->
      <div class="line"></div>
      <div id="publications">
      <details open>
      <summary class="subsection">Publications</summary>

      <h3> 2025</h3>
      <table width="800" border="0" cellspacing="10" align="center">
         <td width=200>
            <img class=icon src="images/huh2025.png" width="200" height="120" align=left>
         </td>
         <td align=left valign=top>
            <div class=pub_title>VideoDiff: Human-AI Video Co-Creation with Alternatives
            </div>
            <div class=links>[<a href="https://arxiv.org/html/2502.10190">project</a>][<a href="https://minahuh.com/assets/pdf/VideoDiff_CamReady.pdf">pdf</a>][<a href="https://youtu.be/3BeBYDyl7yE?si=AbNII3JSne-NJtBd">video</a>]
            </div>
            <p class=authors>M. Huh, D. Li, K. Pimmel, <b>V. Shin</b>, A. Pavel, M. Dontcheva
            </p>
            <div class=conf>
               CHI 2025
            <div>
         </td>
      </table>

      <table width="800" border="0" cellspacing="10" align="center">
         <td width=200>
            <img class=icon src="images/cao2025.png" width="200" height="120" align=left>
         </td>
         <td align=left valign=top>
            <div class=pub_title>Compositional Structures as Substrates for Human-AI Co-creation Environment: A Design Approach and A Case Study
            </div>
            <div class=links>[<a href="https://videorigami-userstudy.netlify.app/">project</a>][<a href="https://hci.ucsd.edu/papers/videorigami.pdf">pdf</a>][<a href="https://youtu.be/WKmghP_lrTc?si=InF-9SNKFXfna368">video</a>][<a href="https://research.adobe.com/news/an-experimental-new-design-approach-for-human-ai-co-creation/">blog post</a>]
            </div>
            <p class=authors>Y. Cao, Y. Huang, A. Truong, <b>V. Shin</b>, H. Xia
            </p>
            <div class=conf>
               CHI 2025
            <div>
         </td>
      </table>

      <h3> 2023</h3>
      <table width="800" border="0" cellspacing="10" align="center">
         <td width=200>
            <img class=icon src="images/chong2023.png" width="200" height="120" align=left>
         </td>
         <td align=left valign=top>
            <div class=pub_title>SoundToons: Exemplar-Based Authoring of Interactive Audio-Driven Animation Sprites.
            </div>
            <div class=links>[<a href="https://drive.google.com/file/d/1Ym8dlbC7dpuG1tleUK7rpezdIcRtQBH1/view">pdf</a>][<a href="https://www.youtube.com/watch?v=JOmh-Gg1QlQ">video</a>]
            </div>
            <p class=authors>T. Chong, D. Aneja, T. Igarashi, <b> V.Shin</b>
            </p>
            <div class=conf>
               ACM IUI 2023
            <div>
         </td>
      </table>

      <table width="800" border="0" cellspacing="10" align="center">
         <td width=200>
            <img class=icon src="images/ma_2023.png" width="200" height="120" align=left>
         </td>
         <td align=left valign=top>
            <div class=pub_title>Automated Conversion of Music Videos into Lyric Videos.
            </div>
            <div class=links>[<a href="https://majiaju.io/lyric-video">project</a>][<a href="https://arxiv.org/pdf/2308.14922.pdf">pdf</a>][<a href="https://www.youtube.com/watch?v=nZ9kOwvWgIU&ab_channel=ACMSIGCHI">video</a>]
            </div>
            <p class=authors>J. Ma, A. Rao, L. Wei, R. Kazi, <b> V.Shin</b>, M. Agrawala
            </p>
            <div class=conf>
               UIST 2023
            <div>
         </td>
      </table>

      <h3> 2022</h3>

      <table width="800" border="0" cellspacing="10" align="center">
         <td width=200>
            <img class=icon src="images/alonzo2022.png" width="200" height="120" align=left>
         </td>
         <td align=left valign=top>
            <div class=pub_title>Beyond Subtitles Captioning and Visualizing Non-Speech Sounds in User Generated Videos.
            </div>
            <div class=links>[<a href="https://oliveralonzo.com/projects/beyond-subtitles/">project</a>][<a href="https://oliveralonzo.com/assets/pdf/beyond-subtitles.pdf">pdf</a>][<a href="https://youtu.be/OBRjjqG1Ht8">video</a>]
            </div>
            <p class=authors>O. Alonzo, <b> V.Shin</b>, D. Li
            </p>
            <div class=conf>
               ASSETS 2022
            <div>
         </td>
      </table>
      <table width="800" border="0" cellspacing="10" align="center">
         <td width=200>
            <img class=icon src="images/yang2022.png" width="200" height="120" align=left>
         </td>
         <td align=left valign=top>
            <div class=pub_title>CatchLive: Real-time Summarization of Live Streams with Stream Content and Interaction Data
            </div>
            <div class=links>[<a href="https://catchlive.kixlab.org/">project</a>][<a href="https://dl.acm.org/doi/fullHtml/10.1145/3491102.3517461">pdf</a>][<a href="https://www.youtube.com/watch?v=M7AOIPKDc20&ab_channel=ACMSIGCHI&themeRefresh=1">video</a>]
            </div>
            <p class=authors>S. Yang, J. Yim, J. Kim, <b> V.Shin</b>
            </p>
            <div class=conf>
               CHI 2022
            <div>
         </td>
      </table>

      <h3> 2021</h3>

      <table width="800" border="0" cellspacing="10" align="center">
         <td width=200>
            <img class=icon src="images/motion_pattern_2021.png" width="200" height="120" align=left>
         </td>
         <td align=left valign=top>
            <div class=pub_title>Multi-level Correspondence via Graph Kernels for Editing Vector Graphics Designs
            </div>
            <div class=links>[<a href="https://people.eecs.berkeley.edu/~bjoern/papers/shin-correspondence-gi2021.pdf">pdf</a>][<a href="https://youtu.be/3LRnof9OpJc">video</a>]
               <p class=authors><b> V.Shin</b>, J. Warner, B. Hartmann, C. Gomes, H. Winnemoeller, W. Li
            </p>
            <div class=conf>
               Graphics Interface 2021
            <div>
         </td>
      </table>

      <table width="800" border="0" cellspacing="10" align="center">
         <td width=200>
            <img class=icon src="images/chung_vispoll_2021.png" width="200" height="120" align=left>
         </td>
         <td align=left valign=top>
            <div class=pub_title>
            Beyond Show of Hands: Engaging Viewers via Expressive and Scalable Visual Communication in Live Streaming            </div>
            </div>
            <div class="links">
            [<a href="https://johnr0.github.io/assets/publications/CHI2021-Beyond-Show-of-Hands.pdf">paper</a>]
            </div>
            <p class=authors>J. Chung, <b> V.Shin</b>, H. Xia, L. Wei, R. Kazi
            </p>
            <div class=conf>
               CHI 2021
            <div>
         </td>
      </table>

      <h3> 2020</h3>

      <table width="800" border="0" cellspacing="10" align="center">
         <td width=200>
            <img class=icon src="images/yang2020.png" width="200" height="120" align=left>
         </td>
         <td align=left valign=top>
            <div class=pub_title>
            Snapstream: Snapshot-based Interactions in Live Streaming for Visual Art
            </div>
            <div class="links">[<a href="https://www.youtube.com/watch?v=x62vzVBD4N4">video</a>]
               [<a href="https://saelyne.github.io/snapstream/">project</a>][<a href="https://saelyne.github.io/snapstream/res/CHI2020_Snapstream.pdf">paper</a>]
            </div>
            <p class=authors>S. Yang, C. Kim
               <b>V. Shin</b>, J. Kim
            </p>
            <div class=conf>
               Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems (CHI 2020)
            <div>
         </td>
      </table>

      <table width="800" border="0" cellspacing="10" align="center">
         <td width=200>
            <img class=icon src="images/fraser2020.png" width="200" height="120" align=left>
         </td>
         <td align=left valign=top>
            <div class=pub_title>
            Temporal Segmentation of Creative Live Streams
            </div>
            <div class=links>[<a href="https://ailiefraser.ca/LiveStreamVideoNavigation_CHI2020.pdf">pdf</a>]
            </div>
            <p class=authors>C. Fraser, J. Kim, <b> V. Shin </b>, J. Brandt, M. Dontcheva
            </p>
            <div class=conf>
               Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems (CHI 2020)
            <div>
         </td>
      </table>

      <table width="800" border="0" cellspacing="10" align="center">
         <td width=200>
            <img class=icon src="images/leake2020.png" width="200" height="120" align=left>
         </td>
         <td align=left valign=top>
            <div class=pub_title>
            Generating Audio-Visual Slideshows from Text Articles Using Word Concreteness
            </div>
            <div class=links>[<a href="http://web.stanford.edu/~mleake/projects/concreteness/">project</a>][<a href="http://web.stanford.edu/~mleake/projects/concreteness/files/texttoslideshow-large.pdf">pdf</a>][<a href="https://youtu.be/5JuCMUuHMtY">video</a>]
            </div>
            <p class=authors>M. Leake, <b> V. Shin </b>, J. Kim, M. Agrawala
            </p>
            <div class=conf>
               Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems (CHI 2020)
            <div>
         </td>
      </table>

      <table width="800" border="0" cellspacing="10" align="center">
         <td width=200>
            <img class=icon src="images/willett2020.png" width="200" height="120" align=left>
         </td>
         <td align=left valign=top>
            <div class=pub_title>
            Pose2Pose: Pose Selection and Transfer for 2D Character Animation
            </div>
            <div class="links">[<a href="http://www.norawillett.com/pose2pose/index.html">project</a>][<a href="http://www.norawillett.com/pose2pose/data/paper.pdf">pdf</a>]
            <p class=authors>N. Willett, <b> V. Shin </b>, Z. Jin, W. Li, A. Finkelstein
            </p>
            <div class=conf>
               In 25th International Conference on Intelligent User Interfaces (IUI '20), March 17–20, 2020, Cagliari, Italy.<div>
         </td>
      </table>
      <h3> 2019</h3>

      <table width="800" border="0" cellspacing="10" align="center">
         <td width=200>
            <img class=icon src="images/b_script.jpg" width="200" height="120" align=left>
         </td>
         <td align=left valign=top>
            <div class=pub_title>
            B-Script: Transcript-based B-roll Video Editing with Recommendations
            </div>
            <div class=links>[<a href="https://berndhuber.github.io/bscript/">project</a>][<a href="https://dl.acm.org/citation.cfm?id=3300311">pdf</a>]
            </div>
            <p class=authors>B. Huber,
               <b>V. Shin</b>, B. Russel, O. Wang, G. Mysore
            </p>
            <div class=conf>
               Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems (CHI 2019)
               <div>
         </td>
      </table>

      <h3> 2018</h3>

      <table width="800" border="0" cellspacing="10" align="center">
         <td width=200>
            <img class=icon src="images/dynamicslide.jpg" width="200" height="120" align=left>
         </td>
         <td align=left valign=top>
            <div class=pub_title>
            DynamicSlide: Exploring the Design Space of Reference-based Interaction Techniques for Slide-based Lecture Videos
            </div>
            <div class=links>[<a href="https://www.dropbox.com/s/vy6ro2lbse2qjrf/mm2018-mahciworkshop-dynamicslide-slides.pdf?dl=0">slides</a>][<a href="https://www.dropbox.com/s/39ut8xz2no974g3/mm2018-mahciworkshop-dynamicslide.pdf?dl=0">pdf</a>]
            </div>
            <p class=authors>H. Jung,
               <b>V. Shin</b>, J. Kim
            </p>
            <div class=conf>
               Proceedings of the 2018 Workshop on Multimedia for Accessible Human Computer Interface
            <div>
         </td>
      </table>

      <table width="800" border="0" cellspacing="10" align="center">
         <td width=200>
            <img class=icon src="images/face2voice.png" width="200" height="120" align=left>
         </td>
         <td align=left valign=top>
            <div class=pub_title>
            On Learning Associations of Faces and Voices
            </div>
            <div class=links>[<a href="https://people.csail.mit.edu/changil/assets/face-voice-accv-2018.pdf">pdf</a>]
            </div>
            <p class=authors>C. Kim, <b> V. Shin </b>, T. Oh, A. Kaspar, M. Elgharib, W. Matusik
            </p>
            <div class=conf>
               In Proceedings of Asian Conference on Computer Vision (ACCV 2018)
            <div>
         </td>
      </table>
      </details>
      </div>

      <div class="line"></div>
      <div id="past_projects">
      <details open>
      <summary class="subsection">Past Projects</summary>

      <table width="800" border="0" cellspacing="10" align="center">
         <td width=200>
            <img class=icon src="images/blink.jpg" width="200" height="120" align=left>
         </td>
         <td align=left valign=top>
            <div class=pub_title>Project Blink: Creating the Future of AI-Powered Video Editing</div>
            [<a href="https://research.adobe.com/news/project-blink-creating-the-future-of-ai-powered-video-editing/">blog post</a>][<a href="https://youtu.be/8JbhWih-wro?si=L9nD3QS0bWctkocC">video</a>]
            </div>
            <p>
               Project Blink is an AI-powered, web-based video editing app that transforms video editing. By leveraging the AI's media understanding capabilities, Project Blink allows users to edit by content rather than frame-by-frame. Users can search for words, images, people, and moments in a video, then cut and paste just as they would in a text document, streamlining the video editing workflow.
            </p>
         </td>
      </table>

      </details>
      </div>

      <div class="line"></div>
      <div id="intern_collaborators">
      <details open>
      <summary class="subsection">Past Intern Collaborators</summary>
      <p>
         Adobe Research offers an exceptional internship program for graduate students. Here are a few research interns I have been fortunate to work with. <br>
         If you are a PhD student and interested in a research internship, please send me an email with your CV and a summary of your research interests.
      </p>

      <ul class="collaborators">
         <li><a href="https://oliveralonzo.com/">Oliver Alonzo</a> - DePaul University</li>
         <li><a href="https://saelyne.com/">Saelyne Yang</a> - KAIST</li>
         <li><a href="https://johnr0.github.io/">John Joon Young Chung</a> - Midjourney</li>
         <li><a href="https://ailiefraser.ca/">Ailie Fraser</a> - Adobe Research</li>
         <li><a href="http://norawillett.com/">Nora Willett</a> - CLO Virtual Fashion</li>
      </ul>
      </details>
      </div>
      
      </div>
      <!--end of wrap-->
   </body>
</html>